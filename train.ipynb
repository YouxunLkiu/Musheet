{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80e4451",
   "metadata": {},
   "source": [
    "# Piano to Sheet\n",
    "\n",
    "Converting .wav piano pieces into music sheets.\n",
    "\n",
    "I\n",
    "\n",
    "## Pipeline break down ( beta)\n",
    "\n",
    "1. Loading in the wave file,\n",
    "2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fd603",
   "metadata": {},
   "source": [
    "## Audio Processing  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaff679",
   "metadata": {},
   "source": [
    "For the processing libraries, we will be using pretty_midi to extract out label information from the given midi files.  \n",
    "And for processing our wav audio files. We will be using librosa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c76f67",
   "metadata": {},
   "source": [
    "## Machine Learning Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85047046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa \n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pretty_midi as pm\n",
    "import mido\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26ef70",
   "metadata": {},
   "source": [
    "# Model Saving funtion and Model loading function\n",
    "\n",
    "Having a model saving function and a modle loading function in which we can train the model in small epoch progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccab19",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef91a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_file_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/maestro-v3.0.0.json\"\n",
    "with open(labels_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "all_sets = {}\n",
    "all_sets['train'] = []\n",
    "all_sets['validation'] = []\n",
    "all_sets['test'] = []\n",
    "\n",
    "def sortingsets (data, allsets):\n",
    "    for key in data:\n",
    "        if data[key] == 'train':\n",
    "            all_sets['train'].append(key)\n",
    "        elif data[key] == 'validation':\n",
    "            all_sets['validation'].append(key)\n",
    "        else:\n",
    "            all_sets['test'].append(key)\n",
    "\n",
    "def save_index_to_csv(all_sets):\n",
    "    for key in all_sets:\n",
    "    \n",
    "        path = f\"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/{key}_indicies.csv\"\n",
    "        df = pd.DataFrame({'Index': all_sets[key]})\n",
    "        df.to_csv(path, index=False)\n",
    "\n",
    "def load_index_from_csv(path):\n",
    "    indices = []\n",
    "    with open(path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            indices.append(int(row[0]))\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870b3aa",
   "metadata": {},
   "source": [
    "traindata/maestro-v3.0.0-midi/maestro-v3.0.0/train_indicies.csv  \n",
    "traindata/maestro-v3.0.0-midi/maestro-v3.0.0/test_indicies.csv   \n",
    "traindata/maestro-v3.0.0-midi/maestro-v3.0.0/validation_indicies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043612fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_index_to_csv(all_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0440f3",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "implenting utility functions such as the randomizing the data set for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### making the random seed \n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d296ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomizing the data set index for training purposes\n",
    "def randomizeing(data_set):\n",
    "    ds = np.array(data_set)\n",
    "    np.random.shuffle(ds)\n",
    "    return ds\n",
    "\n",
    "## Select n indices from the givien data set\n",
    "def select_N_randomized_from_set(n, data_set):\n",
    "    nparry = randomizeing(data_set)\n",
    "    return nparry[:n]\n",
    "\n",
    "\n",
    "## ----- ----- ---------- loading function ------------------------------ ##\n",
    "\n",
    "## function loading in the wav function\n",
    "def load_wav_from_index(index):\n",
    "    labels_file_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/maestro-v3.0.0.json\"\n",
    "    with open(labels_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    wav_path = \"traindata/maestro-v3.0.0/maestro-v3.0.0/\" + data['audio_filename'][str(index)]\n",
    "    \n",
    "    return librosa.load(wav_path, sr=None)\n",
    "\n",
    "## function loading in the midi function\n",
    "def load_midi_from_index(index):\n",
    "    labels_file_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/maestro-v3.0.0.json\"\n",
    "    with open(labels_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    midi_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/\" + data['midi_filename'][str(index)]\n",
    "    return pm.PrettyMIDI(midi_path)\n",
    "\n",
    "## ----- ----- -------- Path showing function-------------------------------- ##\n",
    "    \n",
    "## showing the file path audio of the wave\n",
    "def show_wav_path(index):\n",
    "    labels_file_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/maestro-v3.0.0.json\"\n",
    "    with open(labels_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    wav_path = \"traindata/maestro-v3.0.0/maestro-v3.0.0/\" + data['audio_filename'][str(index)]\n",
    "    return wav_path\n",
    "\n",
    "## Showing the file path of the midi file of data[index]\n",
    "def show_midi_path(index):\n",
    "    labels_file_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/maestro-v3.0.0.json\"\n",
    "    with open(labels_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    midi_path = \"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/\" + data['midi_filename'][str(index)]\n",
    "    return midi_path\n",
    "\n",
    "## loading in the wav and midi pair\n",
    "def load_wav_midi_pair(index): ## (wav, midi)\n",
    "    return load_wav_from_index(index), load_midi_from_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12eb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_index_from_csv(\"traindata/maestro-v3.0.0-midi/maestro-v3.0.0/train_indicies.csv\")\n",
    "print(len(train_data))\n",
    "subset_train_data = select_N_randomized_from_set(50, train_data)\n",
    "\n",
    "print(len(subset_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651ce0a",
   "metadata": {},
   "source": [
    "# AUDIO EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abeb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(wav, sr), midi = load_wav_midi_pair(1025)\n",
    "# midi = load_midi_from_index(1025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5babb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "ballade1, sr = load_wav_from_index(505)\n",
    "\n",
    "noised_ballade1 = add_gaussian_noise(ballade1, noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data= ballade1, rate= sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c3118",
   "metadata": {},
   "source": [
    "### Audio Preprocessing functions\n",
    "\n",
    "#### Pretty_midi note\n",
    "The MIDI object is used from the python package pretty_midi.  \n",
    "Using pretty_midi range from 0 to 127. we can later tranform this into the range of 0 to 87 to match a piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dc1cefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\" This function extracts all played notes in the midi Object, which it will be futher trained with the aligne ed wave object\n",
    "    input: pm object\n",
    "    It is good for debugging and seeing the midi object\n",
    "\"\"\"\n",
    "def extract_midi_notes(midi):\n",
    "    notes = []\n",
    "    for instrument in midi.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append({\n",
    "                'pitch': note.pitch,\n",
    "                'start': note.start,\n",
    "                'end': note.end,\n",
    "                'velocity': note.velocity\n",
    "            })\n",
    "    #preprocessing the sort\n",
    "    notes.sort(key=(lambda x: x['start']))\n",
    "    return notes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Wrting a peekable Generator for midi object\"\"\"\n",
    "class PeekableGenerator:\n",
    "    def __init__(self, generator):\n",
    "        self._generator = generator\n",
    "        self._next_item = None\n",
    "        self._has_next = False\n",
    "        self._advance()\n",
    "\n",
    "    def _advance(self):\n",
    "        try:\n",
    "            self._next_item = self._generator.__next__()\n",
    "            self._has_next = True\n",
    "        except StopIteration:\n",
    "            self._next_item = None\n",
    "            self._has_next = False\n",
    "\n",
    "    def peek(self):\n",
    "        if not self._has_next:\n",
    "            raise StopIteration(\"No more elements to peek at.\")\n",
    "        return self._next_item\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self._has_next:\n",
    "            raise StopIteration(\"No more elements.\")\n",
    "        current = self._next_item\n",
    "        self._advance()\n",
    "        return current\n",
    "\n",
    "    def has_next(self):\n",
    "        return self._has_next\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self._next_item\n",
    "        self._advance()\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"Generator to yield midi note object at the frame during the classification\n",
    "    input: pm object\n",
    "\"\"\"\n",
    "def midi_yielding(midi):\n",
    "    all_midi_obj :list = extract_midi_notes(midi)\n",
    "    ##Processing\n",
    "    for note in all_midi_obj:\n",
    "        yield note\n",
    "\n",
    "\n",
    "\"\"\" Yielding a list of midi notes information where it fits the time frame automatically.\n",
    "    Implemented using overlapping frame structure for the training.\n",
    "    Begin at 0, the frame jumping at the speed of jump_len, the size of the frame is frame_len\n",
    "    This function will yield the frame at the given parameter.\n",
    "\"\"\"\n",
    "def frame_aligning_midi(t: int, jump_len:int, frame_len: int, sr:int, midi):\n",
    "    midi_generator = PeekableGenerator(midi_yielding(midi))\n",
    "    midi_labels = []\n",
    "\n",
    "    jump_time_fraction: float = jump_len * (1/sr)\n",
    "    frame_time_fraction: float = frame_len * (1/sr)\n",
    "    print(f\"The frame jumping rate is at {jump_time_fraction} seconds, and the size of the frame is at {frame_time_fraction}.\")\n",
    "    framing = [t*jump_time_fraction, t*jump_time_fraction + frame_time_fraction]\n",
    "    \n",
    "    last_note = 0\n",
    "    while midi_generator.has_next() or last_note > framing[0]:\n",
    "        \n",
    "        while midi_generator.has_next() and midi_generator.peek()['start'] >= framing[0] and midi_generator.peek()['start'] < framing[1]:\n",
    "            try:\n",
    "                midi_labels.append(midi_generator.__next__())\n",
    "            except StopIteration:\n",
    "                print(\"Generator exhausted, no Midi Objectis being added to the label\")\n",
    "                break\n",
    "        \n",
    "        ## Yielding the list of midi notes that are fitted in side the frame\n",
    "        yield midi_labels\n",
    "\n",
    "        midi_labels.sort(key=(lambda x: x['end']))\n",
    "        ##calculating the next frame time step and removing the items from the previous frame\n",
    "        framing [0] += jump_time_fraction\n",
    "        framing [1] += jump_time_fraction\n",
    "        while len(midi_labels) > 0 and midi_labels[0]['end'] < framing[0]:\n",
    "            midi_labels.pop(0)\n",
    "        \n",
    "        if len(midi_labels) > 0 and midi_labels[0]['end'] > framing[0]:\n",
    "            last_note = midi_labels[0]['end']\n",
    "\n",
    "    \n",
    "        \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" This function returns the aligned frame at the wav data,\"\"\"\n",
    "def frame_aligning_wav(t: int, jump_len: int, frame_len: int, wav):\n",
    "    begin = t * jump_len\n",
    "    return wav[begin: begin + frame_len]\n",
    "\n",
    "\n",
    "\"\"\" This function returns the amount seconds of audio data from the wav, began on t, while using  \"\"\"\n",
    "\n",
    "def audio_segment_of(t: int, wav, seconds: float, sr: int, jump_len: int = 512, frame_len: int = 2048, ):\n",
    "    size = int(seconds*sr)\n",
    "    begin = t*jump_len\n",
    "    \n",
    "    return wav[begin: begin + size]\n",
    "\n",
    "def audio_segment_between(begin, end, wav, sr):\n",
    "    return wav[int(begin*sr): int(end*sr)]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c0e13",
   "metadata": {},
   "source": [
    "### Constructing Mel Spectrogram From wav frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7622f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ballade1, sr), midi = load_wav_midi_pair(505)\n",
    "\n",
    "for i in frame_aligning_midi(0, 512, 2048, sr, midi):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd542b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ballade1, sr = load_wav_from_index(505)\n",
    "audio = audio_segment_of(0, ballade1, 3, sr)\n",
    "audio1 = audio_segment_between(500,501,ballade1, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8986a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data= audio1, rate= sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(audio, sr, n_mels=88, hop_length=512, n_fft=2048): ##_fft is the frame length \n",
    "    \"\"\"\n",
    "    Extract a mel-spectrogram from raw audio.\n",
    "    \"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_mels=n_mels, hop_length=hop_length, n_fft=n_fft\n",
    "    )\n",
    "    # Convert to log scale\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "# Example audio input\n",
    "mel_spectrogram = extract_mel_spectrogram(audio1, sr)\n",
    "\n",
    "# Normalize the spectrogram for display\n",
    "mel_spectrogram_normalized = (mel_spectrogram - mel_spectrogram.min()) / (mel_spectrogram.max() - mel_spectrogram.min())\n",
    "\n",
    "# Plot the mel-spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mel_spectrogram_normalized, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-Spectrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d73318",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e9eb5b8",
   "metadata": {},
   "source": [
    "### Calculating the added noise level to the wav function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_noise_power(audio, snr_dB):\n",
    "    \"\"\"\n",
    "    Compute the noise power needed for a given SNR in dB.\n",
    "    :param audio: NumPy array of the audio signal.\n",
    "    :param snr_dB: Desired Signal-to-Noise Ratio in dB.\n",
    "    :return: Noise power.\n",
    "    \"\"\"\n",
    "    # Calculate signal power (mean squared amplitude)\n",
    "    signal_power = np.mean(audio ** 2)\n",
    "    \n",
    "    # Convert SNR from dB to linear scale\n",
    "    snr_linear = 10 ** (snr_dB / 10)\n",
    "    \n",
    "    # Calculate noise power\n",
    "    noise_power = signal_power / snr_linear\n",
    "    return noise_power\n",
    "\n",
    "div = 100\n",
    "somewav = select_N_randomized_from_set(div, train_data)\n",
    "print(len(somewav))\n",
    "summing = 0 #summing the proper noise level\n",
    "for i in range(10):\n",
    "    wav, _ = load_wav_from_index(somewav[i])\n",
    "    summing += np.sqrt(compute_noise_power(wav, 20)) ## desired training SNR to be 15 dB\n",
    "\n",
    "print(f\"Our desired training noise is about {summing/div}, setting it to be our default added noise to wav\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c50b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(audio, noise_level=0.0006):\n",
    "    \n",
    "    noise = np.random.normal(0, noise_level, audio.shape)\n",
    "    return audio + noise\n",
    "\n",
    "def framelining (time, jump, sr):\n",
    "    \n",
    "    frametime = jump/sr\n",
    "    print(22*frametime)\n",
    "\n",
    "framelining(1, 2048, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04663d46",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b78ededb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"This function generates the matrix label to aligne the mal_spectral gram\n",
    "each matrix should consired num_frame,\n",
    "poping fram_jumping after the matrix is being yield\n",
    "\n",
    "jumping time should be\n",
    "frame_jumping * (frame_len /sr)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def label_generator(num_frame, frame_jumping, jump_len:int, frame_len: int, sr:int, midi):\n",
    "    midi_frame_gen = PeekableGenerator(frame_aligning_midi(0, frame_len, frame_len, sr, midi)) ## Note, while using the architechture of mel_spectrogram, the we don't need to consider the jump offset in the midi side\n",
    "    label = []\n",
    "    counter = 0\n",
    "    \n",
    "    \n",
    "    concur_time = 0\n",
    "    concur_time_end = 0\n",
    "    frame_time = frame_len /sr\n",
    "\n",
    "    \n",
    "    while midi_frame_gen.has_next():\n",
    "        if (len(label) < num_frame):\n",
    "            label.append(list(midi_frame_gen.__next__()))\n",
    "            concur_time_end += frame_time\n",
    "            \n",
    "        else:\n",
    "            counter+=1\n",
    "            yield label\n",
    "            print(f\"label generator output is {concur_time}, {concur_time_end}\")\n",
    "           \n",
    "        \n",
    "            for i in range(int(frame_jumping)):\n",
    "                label.pop(0)\n",
    "                concur_time += frame_time\n",
    "                \n",
    "\n",
    "\n",
    "\"\"\"This function tries to mimic the decayed velocity miniking the sound at which a piano has been decayed\"\"\"\n",
    "def velocity_decay_sustain (velocity, onset, at_time):\n",
    "    if (at_time - onset < 0.2):\n",
    "        return velocity\n",
    "    else:\n",
    "        return math.exp((onset - at_time) * 0.6) * velocity\n",
    "\n",
    "\n",
    "\"\"\"formating the label of list, in to a matrix of 88 * 3 matrix.\n",
    "    each row represent a strikable key, \n",
    "    column 1 (being stricked) : 0, 1 (classification purpose)\n",
    "    column 2 (onset timer) : the set of positive interger that is less than onset. (Regression purpose)\n",
    "    column 3 (velocity of which is being stricked) : the set of positive integer that is less than onset. (Regression purpose) \n",
    "        note for the velocity of the piano key will be approximately alingned with a decay parameter\"\"\"\n",
    "def label_formater(label, frameonset):\n",
    "    ret_label = np.zeros((88,3))\n",
    "    \n",
    "    print(label)\n",
    "    for frame in label :\n",
    "        for key_obj in frame:\n",
    "            pitch = key_obj['pitch'] - 20\n",
    "            ret_label[pitch][0] = 1\n",
    "            ret_label[pitch][1] = key_obj['start'] if key_obj['start'] > frameonset else frameonset\n",
    "            ret_label[pitch][2] = velocity_decay_sustain(key_obj['velocity'],  key_obj['start'], frameonset) \n",
    "\n",
    "    return ret_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"This function assure the input for the training will retain the dimension in the case of track is ending.\"\"\"\n",
    "def construct_input(spectrogram, x, y):\n",
    "    if spectrogram.shape == (x,y):\n",
    "        return spectrogram\n",
    "    else: \n",
    "        ret = np.zeros((x,y))\n",
    "        for i in range(spectrogram.shape[0]):\n",
    "            ret[i] = spectrogram[i]\n",
    "        return ret\n",
    "\n",
    "def train_segment(wav, sr, length=1, hop=0.5):\n",
    "    ret = []\n",
    "    max = len(wav)/sr\n",
    "    begin = 0\n",
    "    \n",
    "    print((begin < max))\n",
    "    while (begin < max):\n",
    "        adding = length if begin + length < max else max - begin\n",
    "        ret.append((begin, begin + adding))\n",
    "        begin += hop\n",
    "\n",
    "    return ret\n",
    "    \n",
    "\n",
    "\"\"\"The training is based on how many frame should be trained at a time,\n",
    "    the default setting is suited for the expriment set up above,\n",
    "    num_frame is tried to aligned it to approx 1 second of the sample\n",
    "    segment_jumping would be trying to get 50% of the sample audio\n",
    "\"\"\"\n",
    "def training(model, index, num_frame=22, segment_jump = 0.5, frame_length = 2048, hop_length = 512):\n",
    "    #load model \n",
    "\n",
    "\n",
    "    # fetching infomation\n",
    "    (wav, sr), midi = load_wav_midi_pair(index)\n",
    "    \n",
    "    frame_time =  frame_length/sr\n",
    "    quick_sample = audio_segment_between(0, num_frame*frame_time, wav, sr)\n",
    "    x, y = extract_mel_spectrogram(quick_sample, sr).shape\n",
    "    segments = train_segment(wav, sr, length = num_frame * frame_time, hop= num_frame * frame_time/2)\n",
    "    print(segments[0])\n",
    "    label_gen = PeekableGenerator(label_generator(num_frame, num_frame*segment_jump, hop_length, frame_length, sr, midi))\n",
    "    \n",
    "    for beg, end in segments:\n",
    "        \n",
    "        if (label_gen.has_next() is False) :\n",
    "            break\n",
    "\n",
    "        audio = audio_segment_between(beg, end, wav, sr)\n",
    "        mel_spectrogram = extract_mel_spectrogram(audio, sr, hop_length= hop_length, n_fft=frame_length)\n",
    "        input_data = construct_input(mel_spectrogram, x,y)\n",
    "        label = label_formater(label_gen.__next__(), beg)\n",
    "        print(f\"input data shape{input_data.shape}\")\n",
    "        print(f\"label's shape{label.shape}\")\n",
    "        break\n",
    "    \n",
    "    #save model \n",
    "\n",
    "\n",
    "\n",
    "def partial_training(model, time_begin, time_end, wav, sr, midi):\n",
    "    return 0\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "472423a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(0, 1.0216780045351475)\n",
      "The frame jumping rate is at 0.046439909297052155 seconds, and the size of the frame is at 0.046439909297052155.\n",
      "label generator output is 0, 1.021678004535147\n",
      "[[], [], [], [], [], [], [], [], [], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}], [{'pitch': 48, 'start': np.float64(0.9854166666666666), 'end': np.float64(1.809375), 'velocity': 87}, {'pitch': 36, 'start': np.float64(0.9874999999999999), 'end': np.float64(1.8968749999999999), 'velocity': 83}]]\n",
      "input data shape(88, 89)\n",
      "label's shape(88, 3)\n"
     ]
    }
   ],
   "source": [
    "training(123, 505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e365498",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_gen = PeekableGenerator(label_generator(22, 22*0.5, 512, 2048, sr, midi))\n",
    "(ballade1, sr), midi= load_wav_midi_pair(505)\n",
    "audio = audio_segment_of(0, ballade1, 3, sr)\n",
    "audio1 = audio_segment_between(500,501,ballade1, sr)\n",
    "segm = train_segment(ballade1, sr, length = 22* 2048/sr, hop= 22* 2048/sr/2)\n",
    "print(len(segm))\n",
    "print(segm[-1])\n",
    "print(segm[-2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "while label_gen.has_next() or counter < len(segm):\n",
    "    if (counter < len(segm)):\n",
    "        print(f\"time segment function o  {segm[counter]}\")\n",
    "        counter+=1\n",
    "    if (label_gen.has_next()):\n",
    "        print(label_gen.__next__())\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc47052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## num_frame=22, segment_jump = 0.5, frame_length = 2048, hop_length = 512\n",
    "(ballade1, sr), midi= load_wav_midi_pair(505)\n",
    "audio = audio_segment_of(0, ballade1, 3, sr)\n",
    "audio1 = audio_segment_between(500,501,ballade1, sr)\n",
    "segm = train_segment(ballade1, sr, length = 22* 2048/sr, hop= 22* 2048/sr/2)\n",
    "print(len(segm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c397eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ballade1)/sr)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42ac20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
